{
    "dataset_reader": {
        "type": "bert_reader",
        "dupe_factor": 1,
        "lazy": false,
        "masked_lm_prob": 0.15,
        "max_predictions_per_seq": 3,
        "max_seq_length": 64,
        "short_seq_prob": 0.1,
        "token_indexers": {
            "tokens": {
                "type": "single_id",
                "lowercase_tokens": true
            }
        },
        "tokenizer": {
            "type": "word",
            "end_tokens": [],
            "word_splitter": {
                "type": "bert-basic",
                "do_lower_case": true
            }
        }
    },
    "iterator": {
        "type": "bucket",
        "batch_size": 256,
        "sorting_keys": [
            [
                "tokens",
                "num_tokens"
            ]
        ]
    },
    "model": {
        "type": "bert",
        "initializer": [],
        "text_field_embedder": {
            "type": "basic_v2",
            "tokens": {
                "type": "embedding_v2",
                "embedding_dim": 200,
                "padding_index": 0,
                "pretrained_file": "/home/icepine.hans/data/ChineseEmbedding.tar.gz",
                "trainable": true
            },
            "use_fp16": false
        },
        "transformer_encoder": {
            "type": "transformer_encoder",
            "attention_dropout_prob": 0.1,
            "attention_type": "dot_product",
            "dropout_prob": 0.1,
            "input_size": 200,
            "intermediate_act_fn": "gelu",
            "intermediate_size": 3072,
            "key_depth": 1024,
            "max_position_embeddings": 256,
            "memory_size": 200,
            "num_heads": 16,
            "num_hidden_layers": 16,
            "type_vocab_size": 2,
            "use_fp16": false,
            "value_depth": 1024
        },
        "wait_user_input": false,
        "use_fp16": false,
    },
    "train_data_path": "/home/icepine.hans/data/bert_shenma_data.2M.txt",
    "validation_data_path": "/home/icepine.hans/data/bert_shenma_data.validate.txt",
    "trainer": {
        "cuda_device": -1,
        "grad_clipping": 0.1,
        "num_epochs": 280,
        "optimizer": {
            "type": "bert_adam",
            "lr": 0.00001
        },
        "patience": 20,
        "validation_metric": "+accuracy"
    }
}
